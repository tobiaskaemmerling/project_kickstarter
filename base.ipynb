{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has no none entry so it is not necessary to drop any rows\n",
    "# Transform categorical string columns to numerical values and keep a dictionary to map them back\n",
    "def transform_strings_to_numerical(data):\n",
    "    \"\"\"\n",
    "    This function transforms all string values in the dataframe to numerical values using the LabelEncoder from sklearn.\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "        transform_data : A dictionary containing the mapping from the original string values to the numerical values\n",
    "    \"\"\"\n",
    "\n",
    "    transform_data = {}\n",
    "    for column in data.columns:\n",
    "        # If data type is an object, for example a string, we want to convert the column to numerical values\n",
    "        if data[column].dtype == 'object' and data[column].dtype != 'datetime64[ns]':\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "            # Save the mapping in a dictionary\n",
    "            transform_data[column] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    return data, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_numerical_to_string(data,transform_data):\n",
    "    \"\"\"\n",
    "    This function transforms all numerical values in the dataframe back to the original string values using the LabelEncoder from sklearn.\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "        transform_data : A dictionary containing the mapping from the original string values to the numerical values\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "    \"\"\"\n",
    "    for column, mapping in transform_data.items():\n",
    "        #print(f\"Mapping for column {column}: {mapping}\")\n",
    "        #if one of the mapped columns is not in the data anymore, we skip it\n",
    "        if column not in data.columns:\n",
    "            continue\n",
    "        # need to reverse the mapping to map back to the original string values\n",
    "        # this simply swaps the keys and values in the dictionary\n",
    "        reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "        # now we can convert back to the original string values\n",
    "        data[column] = data[column].map(reverse_mapping)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Returns the data from the csv file and transforms the categorical values to numerical values\n",
    "    \"\"\"\n",
    "    # read in the data from the csv file\n",
    "    data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "    # transform the categorical values to numerical values\n",
    "\n",
    "    data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "    data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "    data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "\n",
    "    data, transform_data = transform_strings_to_numerical(data)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    We have converted Deadline and Launched to DateTime objects and calculated the duration in days\n",
    "    We also, at least for now, drop all live or suspended or canceled projects\n",
    "    \n",
    "    \"\"\"\n",
    "    #return the data and the transformation_data in case we want to transform the data back\n",
    "    return data, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: State, dtype: int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, transform_data= get_data()\n",
    "data.drop(\"Name\", axis=1, inplace=True)\n",
    "data.head(20)\n",
    "\n",
    "data = transform_numerical_to_string(data,transform_data)\n",
    "data[\"State\"].groupby(data[\"State\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data():\n",
    "    \"\"\"\n",
    "    Returns the original data without any modifications\n",
    "    \"\"\"\n",
    "    # read in the data from the csv file\n",
    "    data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "\n",
    "\n",
    "    data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "    data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "    data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    We have converted Deadline and Launched to DateTime objects and calculated the duration in days\n",
    "    We also, at least for now, drop all live or suspended or canceled projects\n",
    "    \n",
    "    \"\"\"\n",
    "    #return the data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Country</th>\n",
       "      <th>Launched</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Goal</th>\n",
       "      <th>Pledged</th>\n",
       "      <th>Backers</th>\n",
       "      <th>State</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Name, Category, Subcategory, Country, Launched, Deadline, Goal, Pledged, Backers, State, Duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_original_data().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(data,columns,threshold=3):\n",
    "    \"\"\"\n",
    "    This function removes outliers from the data based on the threshold\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "        columns : The columns which we want to check for outliers\n",
    "        threshold : The threshold which we use to determine if a value is an outlier\n",
    "        Multiplied by the standard deviation of the column to determine the range of values which are not outliers\n",
    "        I advise setting the threshold to 3\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    for column in columns:\n",
    "        data = data[np.abs(data[column]-data[column].mean()) <= (threshold*data[column].std())]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train,X_test,y_train,y_test,metric=\"accuracy\",verbose=False,norm=\"l2\",max_iter=1000,C=1.0):\n",
    "    \"\"\"\n",
    "    This function performs logistic regression on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y : The target values\n",
    "        y_train : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model\n",
    "        norm : The norm to use for the logistic regression\n",
    "        max_iter : The maximum number of iterations for the logistic regression\n",
    "        C : The regularization parameter for the logistic regression\n",
    "\n",
    "    Returns:\n",
    "        metric : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # create a logistic regression model\n",
    "    model = LogisticRegression(max_iter=max_iter,penalty=norm,C=C)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Coefficients: {model.coef_}\")\n",
    "        print(f\"Model Intercept: {model.intercept_}\")\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(model,parameters,metric,X_train,X_test,y_train,y_test):\n",
    "    from itertools import product\n",
    "    \"\"\"\n",
    "    \n",
    "    Perform grid search for the given machine learning model and hyperparameters to find the best hyperparameters\n",
    "\n",
    "    Parameters:\n",
    "    model - The machine learning model function to use\n",
    "    param_grid - The hyperparameters to test, given in form of a list of dictionaries\n",
    "    metric - A string specifying the metric to use for evaluation\n",
    "    X_train, X_test, y_train, y_test - The training and test data\n",
    "\n",
    "    Returns: A pandas Dataframe containing the hyperparameters and the corresponding metric value, \n",
    "    sorted by the metric value in descending order\n",
    "\n",
    "    \"\"\"\n",
    "    # Create all possible permutations of the hyperparameters, so if a={1,2} and b={3,4} we get [{1,3},{1,4},{2,3},{2,4}]\n",
    "    keys, values = zip(*parameters.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    # Create a list to store the results\n",
    "    results = []\n",
    "\n",
    "    for params in permutations:\n",
    "        # feed the model with the hyperparameters\n",
    "        # ** unpacks the dictionary into the form dict[key]=value -> key = value\n",
    "        metric_value = model(X_train,X_test,y_train,y_test,**params)\n",
    "\n",
    "        # Append the results to the list\n",
    "        results.append((params, metric_value))\n",
    "\n",
    "    # After the loop is done, we sort the results by the metric value\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = pd.DataFrame(results, columns=['Parameters', metric])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID    Name  Category  Subcategory  Country            Launched   \n",
      "0  1860890148  115746         5           52       21 2009-04-21 21:02:48  \\\n",
      "1   709707365   56298         6          129       21 2009-04-23 00:07:53   \n",
      "2  1703704063  323842         0           70       21 2009-04-24 21:52:03   \n",
      "3      727286  192565        13          131       21 2009-04-25 17:36:21   \n",
      "4  1622952265  200031         5           52       21 2009-04-27 14:10:39   \n",
      "\n",
      "    Deadline   Goal  Pledged  Backers  State  Duration  \n",
      "0 2009-05-31   1000      625       30      0        39  \n",
      "1 2009-07-20  80000       22        3      0        87  \n",
      "2 2009-05-03     20       35        3      1         8  \n",
      "3 2009-07-14     99      145       25      1        79  \n",
      "4 2009-05-26   1900      387       10      0        28  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((265169, 9), (66293, 9), (265169,), (66293,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test out the functions\n",
    "data,transform_data = get_data()\n",
    "print(data.head())\n",
    "\n",
    "y = data['State']\n",
    "X = data.drop(['State','Launched','Deadline'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1337)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 10.0, 'max_iter': 1000}</td>\n",
       "      <td>0.999110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.1, 'max_iter': 1000}</td>\n",
       "      <td>0.999095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 1.0, 'max_iter': 1000}</td>\n",
       "      <td>0.999095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 10.0, 'max_iter': 100}</td>\n",
       "      <td>0.998989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'max_iter': 100}</td>\n",
       "      <td>0.998884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Parameters  accuracy\n",
       "0  {'C': 10.0, 'max_iter': 1000}  0.999110\n",
       "1   {'C': 0.1, 'max_iter': 1000}  0.999095\n",
       "2   {'C': 1.0, 'max_iter': 1000}  0.999095\n",
       "3   {'C': 10.0, 'max_iter': 100}  0.998989\n",
       "4    {'C': 0.1, 'max_iter': 100}  0.998884"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import warnings\n",
    "#\n",
    "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "hyperparameters = {\"C\":[0.1,1.0,10.0],\"max_iter\":[10,100,1000]}\n",
    "results = grid_search(logistic_regression,hyperparameters,\"accuracy\",X_train,X_test,y_train,y_test)\n",
    "\n",
    "results.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
