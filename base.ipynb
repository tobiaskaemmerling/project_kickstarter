{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has no none entry so it is not necessary to drop any rows\n",
    "# Transform categorical string columns to numerical values and keep a dictionary to map them back\n",
    "def transform_strings_to_numerical(data):\n",
    "    \"\"\"\n",
    "    This function transforms all string values in the dataframe to numerical values using the LabelEncoder from sklearn.\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "        transform_data : A dictionary containing the mapping from the original string values to the numerical values\n",
    "    \"\"\"\n",
    "\n",
    "    transform_data = {}\n",
    "    for column in data.columns:\n",
    "        # If data type is an object, for example a string, we want to convert the column to numerical values\n",
    "        if data[column].dtype == 'object' and data[column].dtype != 'datetime64[ns]':\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "            # Save the mapping in a dictionary\n",
    "            transform_data[column] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    return data, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_numerical_to_string(data,transform_data):\n",
    "    \"\"\"\n",
    "    This function transforms all numerical values in the dataframe back to the original string values using the LabelEncoder from sklearn.\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "        transform_data : A dictionary containing the mapping from the original string values to the numerical values\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "    \"\"\"\n",
    "    for column, mapping in transform_data.items():\n",
    "        #print(f\"Mapping for column {column}: {mapping}\")\n",
    "        #if one of the mapped columns is not in the data anymore, we skip it\n",
    "        if column not in data.columns:\n",
    "            continue\n",
    "        # need to reverse the mapping to map back to the original string values\n",
    "        # this simply swaps the keys and values in the dictionary\n",
    "        reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "        # now we can convert back to the original string values\n",
    "        data[column] = data[column].map(reverse_mapping)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Returns the data from the csv file and transforms the categorical values to numerical values\n",
    "    \"\"\"\n",
    "    # read in the data from the csv file\n",
    "    data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "    # transform the categorical values to numerical values\n",
    "\n",
    "    data = data.drop([\"ID\",\"Name\"],axis=1)\n",
    "    data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "    data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "    data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "    data, transform_data = transform_strings_to_numerical(data)\n",
    "\n",
    "    \"\"\"\n",
    "    We have converted Deadline and Launched to DateTime objects and calculated the duration in days\n",
    "    We also, at least for now, drop all live or suspended or canceled projects\n",
    "    \n",
    "    \"\"\"\n",
    "    #return the data and the transformation_data in case we want to transform the data back\n",
    "    return data, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data():\n",
    "    \"\"\"\n",
    "    Returns the original data without any modifications\n",
    "    \"\"\"\n",
    "    # read in the data from the csv file\n",
    "    data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "\n",
    "    data = data.drop([\"ID\",\"Name\"],axis=1)\n",
    "    data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "    data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "    data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "    \"\"\"\n",
    "    We have converted Deadline and Launched to DateTime objects and calculated the duration in days\n",
    "    We also, at least for now, drop all live or suspended or canceled projects\n",
    "    \n",
    "    \"\"\"\n",
    "    #return the data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(data,columns,threshold=3):\n",
    "    \"\"\"\n",
    "    This function removes outliers from the data based on the threshold\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "        columns : The columns which we want to check for outliers\n",
    "        threshold : The threshold which we use to determine if a value is an outlier\n",
    "        Multiplied by the standard deviation of the column to determine the range of values which are not outliers\n",
    "        I advise setting the threshold to 3\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    for column in columns:\n",
    "        data = data[np.abs(data[column]-data[column].mean()) <= (threshold*data[column].std())]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train,X_test,y_train,y_test,metric=\"accuracy\",verbose=False,norm=\"l2\",max_iter=1000,C=1.0):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \"\"\"\n",
    "    This function performs logistic regression on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y : The target values\n",
    "        y_train : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model and the confusion matrix\n",
    "        norm : The norm to use for the logistic regression\n",
    "        max_iter : The maximum number of iterations for the logistic regression\n",
    "        C : The regularization parameter for the logistic regression\n",
    "\n",
    "    Returns:\n",
    "        metric_value : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # create a logistic regression model\n",
    "    model = LogisticRegression(max_iter=max_iter,penalty=norm,C=C)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Coefficients: {model.coef_}\")\n",
    "        print(f\"Model Intercept: {model.intercept_}\")\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "        print(f'Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(model,parameters,metric,X_train,X_test,y_train,y_test):\n",
    "    from itertools import product\n",
    "    \"\"\"\n",
    "    \n",
    "    Perform grid search for the given machine learning model and hyperparameters to find the best hyperparameters\n",
    "\n",
    "    Parameters:\n",
    "    model - The machine learning model function to use\n",
    "    param_grid - The hyperparameters to test, given in form of a list of dictionaries\n",
    "    metric - A string specifying the metric to use for evaluation\n",
    "    X_train, X_test, y_train, y_test - The training and test data\n",
    "\n",
    "    Returns: A pandas Dataframe containing the hyperparameters and the corresponding metric value, \n",
    "    sorted by the metric value in descending order\n",
    "\n",
    "    \"\"\"\n",
    "    # Create all possible permutations of the hyperparameters, so if a={1,2} and b={3,4} we get [{1,3},{1,4},{2,3},{2,4}]\n",
    "    keys, values = zip(*parameters.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    # Create a list to store the results\n",
    "    results = []\n",
    "\n",
    "    for params in permutations:\n",
    "        # feed the model with the hyperparameters\n",
    "        # ** unpacks the dictionary into the form dict[key]=value -> key = value\n",
    "        metric_value = model(X_train,X_test,y_train,y_test,**params)\n",
    "\n",
    "        # Append the results to the list\n",
    "        results.append((params, metric_value))\n",
    "\n",
    "    # After the loop is done, we sort the results by the metric value\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = pd.DataFrame(results, columns=['Parameters', metric])\n",
    "\n",
    "    return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train,X_test,y_train,y_test,metric=\"accuracy\",verbose=False):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \"\"\"\n",
    "    This function performs logistic regression on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y_train : The target values\n",
    "        y_test : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model and the confusion matrix\n",
    "\n",
    "    Returns:\n",
    "        metric_value : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # create a decision tree model\n",
    "    model = DecisionTreeClassifier()\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "        print(f\"Confusion Matrix\\n: {confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(X_train,X_test,y_train,y_test,metric=\"accuracy\",booster=\"gbtree\",eta=0.3,max_depth=6, reg_lambda=1, verbose=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function performs xgboost on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y_train : The target values\n",
    "        y_test : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model and the confusion matrix\n",
    "        booster : The type of booster to use, Options: \"gbtree\", \"gblinear\", \"dart\"\n",
    "        eta : The learning rate of the model, between [0,1]\n",
    "        max_depth : The maximum depth of the trees, default is 6 to avoid overfitting\n",
    "        reg_lambda : The regularization parameter of the model\n",
    "\n",
    "    Returns:\n",
    "        metric_value : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "    from xgboost import XGBClassifier\n",
    "    # create a logistic regression model\n",
    "    model = XGBClassifier(booster=booster,eta=eta)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "        print(f\"Confusion Matrix\\n: {confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
