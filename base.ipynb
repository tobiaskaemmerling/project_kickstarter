{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has no none entry so it is not necessary to drop any rows\n",
    "# Transform categorical string columns to numerical values and keep a dictionary to map them back\n",
    "def transform_strings_to_numerical(data):\n",
    "    \"\"\"\n",
    "    This function transforms all string values in the dataframe to numerical values using the LabelEncoder from sklearn.\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "        transform_data : A dictionary containing the mapping from the original string values to the numerical values\n",
    "    \"\"\"\n",
    "\n",
    "    transform_data = {}\n",
    "    for column in data.columns:\n",
    "        # If data type is an object, for example a string, we want to convert the column to numerical values\n",
    "        if data[column].dtype == 'object' and data[column].dtype != 'datetime64[ns]':\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "            # Save the mapping in a dictionary\n",
    "            transform_data[column] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    return data, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_numerical_to_string(data,transform_data):\n",
    "    \"\"\"\n",
    "    This function transforms all numerical values in the dataframe back to the original string values using the LabelEncoder from sklearn.\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "        transform_data : A dictionary containing the mapping from the original string values to the numerical values\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "    \"\"\"\n",
    "    for column, mapping in transform_data.items():\n",
    "        #print(f\"Mapping for column {column}: {mapping}\")\n",
    "        #if one of the mapped columns is not in the data anymore, we skip it\n",
    "        if column not in data.columns:\n",
    "            continue\n",
    "        # need to reverse the mapping to map back to the original string values\n",
    "        # this simply swaps the keys and values in the dictionary\n",
    "        reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "        # now we can convert back to the original string values\n",
    "        data[column] = data[column].map(reverse_mapping)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Returns the data from the csv file and transforms the categorical values to numerical values\n",
    "    \"\"\"\n",
    "    # read in the data from the csv file\n",
    "    data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "    # transform the categorical values to numerical values\n",
    "\n",
    "    data = data.drop([\"ID\",\"Name\"],axis=1)\n",
    "    data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "    data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "    data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "\n",
    "    data, transform_data = transform_strings_to_numerical(data)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    We have converted Deadline and Launched to DateTime objects and calculated the duration in days\n",
    "    We also, at least for now, drop all live or suspended or canceled projects\n",
    "    \n",
    "    \"\"\"\n",
    "    #return the data and the transformation_data in case we want to transform the data back\n",
    "    return data, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data():\n",
    "    \"\"\"\n",
    "    Returns the original data without any modifications\n",
    "    \"\"\"\n",
    "    # read in the data from the csv file\n",
    "    data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "\n",
    "    data = data.drop([\"ID\",\"Name\"],axis=1)\n",
    "    data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "    data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "    data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    We have converted Deadline and Launched to DateTime objects and calculated the duration in days\n",
    "    We also, at least for now, drop all live or suspended or canceled projects\n",
    "    \n",
    "    \"\"\"\n",
    "    #return the data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(data,columns,threshold=3):\n",
    "    \"\"\"\n",
    "    This function removes outliers from the data based on the threshold\n",
    "    Args:\n",
    "        data : Our dataframe which we want to modify\n",
    "        columns : The columns which we want to check for outliers\n",
    "        threshold : The threshold which we use to determine if a value is an outlier\n",
    "        Multiplied by the standard deviation of the column to determine the range of values which are not outliers\n",
    "        I advise setting the threshold to 3\n",
    "\n",
    "    Returns:\n",
    "        data : Our modified dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    for column in columns:\n",
    "        data = data[np.abs(data[column]-data[column].mean()) <= (threshold*data[column].std())]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train,X_test,y_train,y_test,metric=\"accuracy\",verbose=False,norm=\"l2\",max_iter=1000,C=1.0):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \"\"\"\n",
    "    This function performs logistic regression on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y : The target values\n",
    "        y_train : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model\n",
    "        norm : The norm to use for the logistic regression\n",
    "        max_iter : The maximum number of iterations for the logistic regression\n",
    "        C : The regularization parameter for the logistic regression\n",
    "\n",
    "    Returns:\n",
    "        metric_value : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # create a logistic regression model\n",
    "    model = LogisticRegression(max_iter=max_iter,penalty=norm,C=C)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Coefficients: {model.coef_}\")\n",
    "        print(f\"Model Intercept: {model.intercept_}\")\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "        print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Subcategory  Country            Launched   Deadline   Goal   \n",
      "0         5           52       21 2009-04-21 21:02:48 2009-05-31   1000  \\\n",
      "1         6          129       21 2009-04-23 00:07:53 2009-07-20  80000   \n",
      "2         0           70       21 2009-04-24 21:52:03 2009-05-03     20   \n",
      "3        13          131       21 2009-04-25 17:36:21 2009-07-14     99   \n",
      "4         5           52       21 2009-04-27 14:10:39 2009-05-26   1900   \n",
      "\n",
      "   Pledged  Backers  State  Duration  \n",
      "0      625       30      0        39  \n",
      "1       22        3      0        87  \n",
      "2       35        3      1         8  \n",
      "3      145       25      1        79  \n",
      "4      387       10      0        28  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((265169, 7), (66293, 7), (265169,), (66293,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test out the functions\n",
    "data,transform_data = get_data()\n",
    "print(data.head())\n",
    "\n",
    "y = data['State']\n",
    "X = data.drop(['State','Launched','Deadline'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1337)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(model,parameters,metric,X_train,X_test,y_train,y_test):\n",
    "    from itertools import product\n",
    "    \"\"\"\n",
    "    \n",
    "    Perform grid search for the given machine learning model and hyperparameters to find the best hyperparameters\n",
    "\n",
    "    Parameters:\n",
    "    model - The machine learning model function to use\n",
    "    param_grid - The hyperparameters to test, given in form of a list of dictionaries\n",
    "    metric - A string specifying the metric to use for evaluation\n",
    "    X_train, X_test, y_train, y_test - The training and test data\n",
    "\n",
    "    Returns: A pandas Dataframe containing the hyperparameters and the corresponding metric value, \n",
    "    sorted by the metric value in descending order\n",
    "\n",
    "    \"\"\"\n",
    "    # Create all possible permutations of the hyperparameters, so if a={1,2} and b={3,4} we get [{1,3},{1,4},{2,3},{2,4}]\n",
    "    keys, values = zip(*parameters.items())\n",
    "    permutations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "    # Create a list to store the results\n",
    "    results = []\n",
    "\n",
    "    for params in permutations:\n",
    "        # feed the model with the hyperparameters\n",
    "        # ** unpacks the dictionary into the form dict[key]=value -> key = value\n",
    "        metric_value = model(X_train,X_test,y_train,y_test,**params)\n",
    "\n",
    "        # Append the results to the list\n",
    "        results.append((params, metric_value))\n",
    "\n",
    "    # After the loop is done, we sort the results by the metric value\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = pd.DataFrame(results, columns=['Parameters', metric])\n",
    "\n",
    "    return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 3}</td>\n",
       "      <td>0.999261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 6}</td>\n",
       "      <td>0.999261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 12}</td>\n",
       "      <td>0.999261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 24}</td>\n",
       "      <td>0.999261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'eta': 1, 'max_depth': 3}</td>\n",
       "      <td>0.999125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Parameters        f1\n",
       "0   {'eta': 0.3, 'max_depth': 3}  0.999261\n",
       "1   {'eta': 0.3, 'max_depth': 6}  0.999261\n",
       "2  {'eta': 0.3, 'max_depth': 12}  0.999261\n",
       "3  {'eta': 0.3, 'max_depth': 24}  0.999261\n",
       "4     {'eta': 1, 'max_depth': 3}  0.999125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import warnings\n",
    "#\n",
    "# warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "hyperparameters = {\"eta\":[0.1,0.3,1],\"max_depth\":[3,6,12,24]}\n",
    "results = grid_search(xgb,hyperparameters,\"f1\",X_train,X_test,y_train,y_test)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Country</th>\n",
       "      <th>Goal</th>\n",
       "      <th>Pledged</th>\n",
       "      <th>Backers</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164774</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>21</td>\n",
       "      <td>3500</td>\n",
       "      <td>3501</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74178</th>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>320</td>\n",
       "      <td>567</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296198</th>\n",
       "      <td>13</td>\n",
       "      <td>138</td>\n",
       "      <td>21</td>\n",
       "      <td>250000</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92665</th>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>21</td>\n",
       "      <td>7000</td>\n",
       "      <td>528</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191647</th>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>21</td>\n",
       "      <td>2000</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Subcategory  Country    Goal  Pledged  Backers  Duration\n",
       "164774         3           99       21    3500     3501       19        29\n",
       "74178         10           90       20     320      567       27        29\n",
       "296198        13          138       21  250000      275        2        29\n",
       "92665          6          129       21    7000      528       23        38\n",
       "191647        12           95       21    2000       80        3        14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\tobia\\anaconda3\\envs\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.1, 'max_iter': 100}</td>\n",
       "      <td>0.999155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.1, 'max_iter': 500}</td>\n",
       "      <td>0.999155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.1, 'max_iter': 1000}</td>\n",
       "      <td>0.999155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 1, 'max_iter': 100}</td>\n",
       "      <td>0.999155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 1, 'max_iter': 500}</td>\n",
       "      <td>0.999155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Parameters        f1\n",
       "0   {'C': 0.1, 'max_iter': 100}  0.999155\n",
       "1   {'C': 0.1, 'max_iter': 500}  0.999155\n",
       "2  {'C': 0.1, 'max_iter': 1000}  0.999155\n",
       "3     {'C': 1, 'max_iter': 100}  0.999155\n",
       "4     {'C': 1, 'max_iter': 500}  0.999155"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"C\":[0.1,1,10],\"max_iter\":[100,500,1000]}\n",
    "results = grid_search(logistic_regression,hyperparameters,\"f1\",X_train,X_test,y_train,y_test)\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [[ 0.02520122  0.00417009  0.04143354 -0.10483769  0.10516741  0.08317194\n",
      "   0.00119811]]\n",
      "Model Intercept: [0.00554605]\n",
      "Model Score: [0 0 0 ... 0 1 0]\n",
      "Confusion Matrix: [[39351    56]\n",
      " [    0 26886]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9989596492531768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X_train,X_test,y_train,y_test,metric=\"f1\",verbose=True,C=0.1,max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train,X_test,y_train,y_test,metric=\"accuracy\",verbose=False):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \"\"\"\n",
    "    This function performs logistic regression on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y_train : The target values\n",
    "        y_test : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model\n",
    "\n",
    "    Returns:\n",
    "        metric_value : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # create a decision tree model\n",
    "    model = DecisionTreeClassifier()\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
    "        disp.plot()\n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(X_train,X_test,y_train,y_test,metric=\"accuracy\",booster=\"gbtree\",eta=0.3,max_depth=6, reg_lambda=1, verbose=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function performs xgboost on the data and returns the accuracy of the model\n",
    "    Necessary Arguments:\n",
    "        X_train : The training data\n",
    "        X_test : The test data\n",
    "        y_train : The target values\n",
    "        y_test : The target values for the training data\n",
    "\n",
    "    Optional Arguments:\n",
    "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
    "        verbose : If True, the function will print the metric of the model\n",
    "        booster : The type of booster to use, Options: \"gbtree\", \"gblinear\", \"dart\"\n",
    "        eta : The learning rate of the model, between [0,1]\n",
    "        max_depth : The maximum depth of the trees, default is 6 to avoid overfitting\n",
    "        reg_lambda : The regularization parameter of the model\n",
    "\n",
    "    Returns:\n",
    "        metric_value : The number of the metric specified in the arguments\n",
    "    \"\"\"\n",
    "    from xgboost import XGBClassifier\n",
    "    # create a logistic regression model\n",
    "    model = XGBClassifier(booster=booster,eta=eta)\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Model Score: {y_pred}\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data.target_names)\n",
    "        disp.plot()\n",
    "        \n",
    "\n",
    "    metric_value = 0\n",
    "    # calculate the metric of the model\n",
    "    if metric == \"accuracy\":\n",
    "        metric_value = accuracy_score(y_test, y_pred)\n",
    "    if metric == \"precision\":\n",
    "        metric_value = precision_score(y_test, y_pred)\n",
    "    if metric == \"recall\":\n",
    "        metric_value = recall_score(y_test, y_pred)\n",
    "    if metric == \"f1\":\n",
    "        metric_value = f1_score(y_test, y_pred)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,transform_data = get_data()\n",
    "data.head()\n",
    "data.groupby(\"State\").count()\n",
    "\n",
    "y = data['State']\n",
    "X = data.drop(['State','Launched','Deadline'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "\n",
    "\n",
    "data = data.drop([\"ID\",\"Name\"],axis=1)\n",
    "data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "data, transform_data = transform_strings_to_numerical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [[ 0.02520122  0.00417009  0.04143354 -0.10483769  0.10516741  0.08317194\n",
      "   0.00119811]]\n",
      "Model Intercept: [0.00554605]\n",
      "Model Score: [0 0 0 ... 0 1 0]\n",
      "Confusion Matrix: [[39351    56]\n",
      " [    0 26886]]\n",
      "0.9989596492531768\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1337)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "model = LogisticRegression(max_iter=1000,penalty=\"l2\",C=0.1)\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the target values for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Model Coefficients: {model.coef_}\")\n",
    "print(f\"Model Intercept: {model.intercept_}\")\n",
    "print(f\"Model Score: {y_pred}\")\n",
    "print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "metric_value = f1_score(y_test, y_pred)\n",
    "print(metric_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
