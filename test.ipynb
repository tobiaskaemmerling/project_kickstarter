{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from base.ipynb\n"
     ]
    }
   ],
   "source": [
    "import base\n",
    "# When having any question about any of the functions in base, you can either look at the\n",
    "# commented code in base.ipynb or use the help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function xgb in module base:\n",
      "\n",
      "xgb(X_train, X_test, y_train, y_test, metric='accuracy', booster='gbtree', eta=0.3, max_depth=6, reg_lambda=1, verbose=False)\n",
      "    This function performs xgboost on the data and returns the accuracy of the model\n",
      "    Necessary Arguments:\n",
      "        X_train : The training data\n",
      "        X_test : The test data\n",
      "        y_train : The target values\n",
      "        y_test : The target values for the training data\n",
      "    \n",
      "    Optional Arguments:\n",
      "        metric : The metric to calculate the model performance, Options: \"accuracy\", \"precision\", \"recall\", \"f1\"\n",
      "        verbose : If True, the function will print the metric of the model\n",
      "        booster : The type of booster to use, Options: \"gbtree\", \"gblinear\", \"dart\"\n",
      "        eta : The learning rate of the model, between [0,1]\n",
      "        max_depth : The maximum depth of the trees, default is 6 to avoid overfitting\n",
      "        reg_lambda : The regularization parameter of the model\n",
      "    \n",
      "    Returns:\n",
      "        metric_value : The number of the metric specified in the arguments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For example\n",
    "help(base.xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9291990537343697\n",
      "Confusion Matrix:\n",
      "  [[37771  1676]\n",
      " [ 4850 21996]]\n",
      "Model Coefficients: [[-0.01076887 -0.0009772  -0.00749205 -0.00023625  0.0545101  -0.01675955]]\n",
      "Model Intercept: [-0.00265765]\n"
     ]
    }
   ],
   "source": [
    "#This is what the code would look like without using any functions\n",
    "\n",
    "#read in the csv file\n",
    "data = pd.read_csv('data/kickstarter_projects.csv')\n",
    "\n",
    "#drop the ID and Name columns, only take the rows where the state is either successful or failed\n",
    "data = data.drop([\"ID\",\"Name\"],axis=1)\n",
    "data = data[(data[\"State\"] == \"Successful\") | (data[\"State\"] == \"Failed\")]\n",
    "\n",
    "#convert the deadline and launched columns to datetime, calculate the duration of the project\n",
    "#and add it as a new column\n",
    "data[\"Deadline\"] = pd.to_datetime(data[\"Deadline\"],format='%Y-%m-%d')\n",
    "data[\"Launched\"] = pd.to_datetime(data[\"Launched\"],format='%Y-%m-%d %H:%M:%S')\n",
    "data[\"Duration\"] = (data[\"Deadline\"] - data[\"Launched\"]).dt.days\n",
    "\n",
    "#transform all the string columns to numerical\n",
    "for column in data.columns:\n",
    "        if data[column].dtype == 'object' and data[column].dtype != 'datetime64[ns]':\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "\n",
    "#split the data into the features and the target and than do train test split\n",
    "y = data['State']\n",
    "# We left in some columns in the Data which might be useful for EDA which we are removing here\n",
    "X = data.drop(['State','Launched','Deadline','Pledged'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=75)\n",
    "\n",
    "# create a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000,penalty=\"l2\",C=0.1)\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "# predict the target values for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the precision, recall, f1 score or accuracy\n",
    "precision = precision_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Confusion Matrix:\\n \", confusion)\n",
    "\n",
    "#These are only for logistic regression, not for the other models\n",
    "print(f\"Model Coefficients: {model.coef_}\")\n",
    "print(f\"Model Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [[-0.01210504 -0.00098262 -0.00667038 -0.00023508  0.05487012 -0.01718795]]\n",
      "Model Intercept: [-0.00382842]\n",
      "Model Score: [1 0 0 ... 1 0 0]\n",
      "Confusion Matrix: [[37735  1759]\n",
      " [ 4716 22083]]\n"
     ]
    }
   ],
   "source": [
    "#This is the code using functions\n",
    "data,transform_data = base.get_data()\n",
    "y = data['State']\n",
    "# We left in some columns in the Data which might be useful for EDA which we are removing here\n",
    "X = data.drop(['State','Launched','Deadline',\"Pledged\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 152)\n",
    "\n",
    "f1 = base.logistic_regression(X_train,X_test,y_train,y_test,metric=\"f1\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: [1 0 0 ... 1 0 0]\n",
      "Confusion Matrix\n",
      ": [[37047  2447]\n",
      " [ 1951 24848]]\n"
     ]
    }
   ],
   "source": [
    "#Making Changes to the model or choosing a different model is as easy as using a different function\n",
    "#in the last line of the code\n",
    "#This code now uses xgboost instead of logistic regression\n",
    "#This is the code using functions\n",
    "data,transform_data = base.get_data()\n",
    "y = data['State']\n",
    "X = data.drop(['State','Launched','Deadline',\"Pledged\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 152)\n",
    "\n",
    "f1 = base.xgb(X_train,X_test,y_train,y_test,metric=\"f1\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using this we were able to get the following scores for our data, using the hyperparameters which are pre-set\n",
    "\n",
    "# decision tree: 87.6% f1score, 90.1% accuracy, 88% precision, 87,5% recall\n",
    "# logistic regression: 87.2% f1score, 90.2% accuracy, 92,6% precision, 82.4% recall \n",
    "# xgboost 92% f1score, 93,3% accuracy, 91% precision, 92,7% recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 3}</td>\n",
       "      <td>0.933658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 6}</td>\n",
       "      <td>0.933658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 12}</td>\n",
       "      <td>0.933658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'eta': 0.3, 'max_depth': 24}</td>\n",
       "      <td>0.933658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'eta': 0.1, 'max_depth': 3}</td>\n",
       "      <td>0.932829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Parameters        f1\n",
       "0   {'eta': 0.3, 'max_depth': 3}  0.933658\n",
       "1   {'eta': 0.3, 'max_depth': 6}  0.933658\n",
       "2  {'eta': 0.3, 'max_depth': 12}  0.933658\n",
       "3  {'eta': 0.3, 'max_depth': 24}  0.933658\n",
       "4   {'eta': 0.1, 'max_depth': 3}  0.932829"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another function is the grid search function. You can declare a set of hyperparameters like below\n",
    "# The grid search function will then try all the combinations of the hyperparameters and return the results\n",
    "# for each combination\n",
    "hyperparameters = {\"eta\":[0.1,0.3,1],\"max_depth\":[3,6,12,24]}\n",
    "\n",
    "# You have to give the grid_search function the name of the function to use, for example here base.xgb, so xgboost\n",
    "results = base.grid_search(base.xgb,hyperparameters,\"f1\",X_train,X_test,y_train,y_test)\n",
    "# It will return a Dataframe including all necessary informations\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters = {\"C\":[0.1,1,10],\"max_iter\":[100,500,1000]}\n",
    "#results = grid_search(logistic_regression,hyperparameters,\"f1\",X_train,X_test,y_train,y_test)\n",
    "#results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: [1 0 0 ... 0 0 1]\n",
      "Confusion Matrix\n",
      ": [[36288  3206]\n",
      " [ 3363 23436]]\n",
      "0.874510242919512\n"
     ]
    }
   ],
   "source": [
    "# decision tree: 87.6% f1score, 90.1% accuracy, 88% precision, 87,5% recall\n",
    "# logistic regression: 87.2% f1score, 90.2% accuracy, 92,6% precision, 82.4% recall \n",
    "# xgboost 92% f1score, 93,3% accuracy, 91% precision, 92,7% recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
